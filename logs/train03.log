2025-10-04 22:02:14,295 INFO Starting trainer with args: {'data': 'data/frames/kepler_summary_with_labels.parquet', 'out': 'models', 'epochs': 1, 'batch_size': 512, 'embed_dim': 64, 'heads': 4, 'layers': 2, 'dropout': 0.1, 'lr': 0.0005, 'sample_frac': 0.02, 'class_weight': False, 'oversample': True, 'clip_grad_norm': 1.0, 'weight_decay': 0.01, 'label_smoothing': 0.05, 'scheduler': 'plateau', 'lr_factor': 0.5, 'lr_patience': 1, 'early_stopping_patience': 2, 'seed': 42, 'log_file': 'logs/train03.log', 'log_interval': 20, 'verbose': True}
2025-10-04 22:02:14,524 INFO Dataset: total=2139 train=1711 val=428
2025-10-04 22:02:14,524 INFO Train class counts: CANDIDATE=310, CONFIRMED=461, FALSE POSITIVE=940
2025-10-04 22:02:14,525 INFO Val class counts:   CANDIDATE=78, CONFIRMED=115, FALSE POSITIVE=235
2025-10-04 22:02:14,525 INFO Num features=53 Cat features=5
2025-10-04 22:02:14,526 INFO Sampler: WeightedRandomSampler (oversampling)
2025-10-04 22:02:14,540 INFO Model: FT-Transformer embed_dim=64 heads=4 layers=2 dropout=0.1
2025-10-04 22:02:15,089 INFO Loss: CrossEntropy label_smoothing=0.050
2025-10-04 22:02:15,089 INFO Optimizer: AdamW lr=0.0005 weight_decay=0.01
2025-10-04 22:02:15,089 INFO Scheduler: ReduceLROnPlateau factor=0.5 patience=1
2025-10-04 22:02:15,089 INFO Training: epochs=1 batch_size=512 steps_per_epoch=4
2025-10-04 22:02:19,212 INFO Epoch 1/1 - lr 0.000500 - loss 1.2519 - val f1 0.4159
2025-10-04 22:02:19,223 INFO Classification report:
                precision    recall  f1-score   support

     CANDIDATE       0.20      0.60      0.30        78
     CONFIRMED       0.43      0.43      0.43       115
FALSE POSITIVE       0.88      0.30      0.44       235

      accuracy                           0.39       428
     macro avg       0.50      0.45      0.39       428
  weighted avg       0.63      0.39      0.42       428

2025-10-04 22:04:50,257 INFO Starting trainer with args: {'data': 'data/frames/kepler_summary_with_labels.parquet', 'out': 'models', 'epochs': 30, 'batch_size': 512, 'embed_dim': 128, 'heads': 8, 'layers': 4, 'dropout': 0.1, 'lr': 0.0002, 'sample_frac': 1.0, 'class_weight': False, 'oversample': True, 'clip_grad_norm': 1.0, 'weight_decay': 0.01, 'label_smoothing': 0.05, 'scheduler': 'plateau', 'lr_factor': 0.5, 'lr_patience': 2, 'early_stopping_patience': 6, 'seed': 42, 'log_file': 'logs/train03.log', 'log_interval': 50, 'verbose': True}
2025-10-04 22:04:50,549 INFO Dataset: total=106978 train=85582 val=21396
2025-10-04 22:04:50,550 INFO Train class counts: CANDIDATE=15543, CONFIRMED=23032, FALSE POSITIVE=47007
2025-10-04 22:04:50,550 INFO Val class counts:   CANDIDATE=3886, CONFIRMED=5758, FALSE POSITIVE=11752
2025-10-04 22:04:50,550 INFO Num features=53 Cat features=5
2025-10-04 22:04:50,579 INFO Sampler: WeightedRandomSampler (oversampling)
2025-10-04 22:04:50,601 INFO Model: FT-Transformer embed_dim=128 heads=8 layers=4 dropout=0.1
2025-10-04 22:04:51,142 INFO Loss: CrossEntropy label_smoothing=0.050
2025-10-04 22:04:51,142 INFO Optimizer: AdamW lr=0.0002 weight_decay=0.01
2025-10-04 22:04:51,142 INFO Scheduler: ReduceLROnPlateau factor=0.5 patience=2
2025-10-04 22:04:51,142 INFO Training: epochs=30 batch_size=512 steps_per_epoch=168
2025-10-04 22:07:30,273 INFO Epoch 1 Step 50/168 - lr 0.000200 - loss 0.9135
2025-10-04 22:10:07,750 INFO Epoch 1 Step 100/168 - lr 0.000200 - loss 0.8080
2025-10-04 22:12:39,544 INFO Epoch 1 Step 150/168 - lr 0.000200 - loss 0.7696
2025-10-04 22:13:52,113 INFO Epoch 1/30 - lr 0.000200 - loss 0.7586 - val f1 0.7458
2025-10-04 22:16:25,934 INFO Epoch 2 Step 50/168 - lr 0.000200 - loss 0.6836
2025-10-04 22:19:02,048 INFO Epoch 2 Step 100/168 - lr 0.000200 - loss 0.6799
2025-10-04 22:21:31,670 INFO Epoch 2 Step 150/168 - lr 0.000200 - loss 0.6777
2025-10-04 22:22:39,606 INFO Epoch 2/30 - lr 0.000200 - loss 0.6760 - val f1 0.7717
2025-10-04 22:29:30,603 INFO Epoch 3 Step 50/168 - lr 0.000200 - loss 0.6710
2025-10-04 22:42:32,060 INFO Epoch 3 Step 100/168 - lr 0.000200 - loss 0.6668
2025-10-04 22:45:02,866 INFO Epoch 3 Step 150/168 - lr 0.000200 - loss 0.6656
2025-10-04 22:46:14,169 INFO Epoch 3/30 - lr 0.000200 - loss 0.6650 - val f1 0.7719
2025-10-04 22:48:49,097 INFO Epoch 4 Step 50/168 - lr 0.000200 - loss 0.6626
2025-10-04 22:51:20,391 INFO Epoch 4 Step 100/168 - lr 0.000200 - loss 0.6584
2025-10-04 22:53:55,018 INFO Epoch 4 Step 150/168 - lr 0.000200 - loss 0.6547
2025-10-04 22:55:04,731 INFO Epoch 4/30 - lr 0.000200 - loss 0.6535 - val f1 0.7787
2025-10-04 22:57:38,054 INFO Epoch 5 Step 50/168 - lr 0.000200 - loss 0.6480
2025-10-04 23:00:18,765 INFO Epoch 5 Step 100/168 - lr 0.000200 - loss 0.6363
2025-10-04 23:02:46,279 INFO Epoch 5 Step 150/168 - lr 0.000200 - loss 0.6363
2025-10-04 23:03:56,986 INFO Epoch 5/30 - lr 0.000200 - loss 0.6346 - val f1 0.7907
2025-10-04 23:06:31,288 INFO Epoch 6 Step 50/168 - lr 0.000200 - loss 0.6163
2025-10-04 23:09:00,366 INFO Epoch 6 Step 100/168 - lr 0.000200 - loss 0.6142
2025-10-04 23:11:38,413 INFO Epoch 6 Step 150/168 - lr 0.000200 - loss 0.6089
2025-10-04 23:12:50,649 INFO Epoch 6/30 - lr 0.000200 - loss 0.6080 - val f1 0.8074
2025-10-04 23:15:21,555 INFO Epoch 7 Step 50/168 - lr 0.000200 - loss 0.5866
2025-10-04 23:17:45,988 INFO Epoch 7 Step 100/168 - lr 0.000200 - loss 0.5810
2025-10-04 23:20:21,681 INFO Epoch 7 Step 150/168 - lr 0.000200 - loss 0.5772
2025-10-04 23:21:31,752 INFO Epoch 7/30 - lr 0.000200 - loss 0.5743 - val f1 0.8173
2025-10-04 23:24:05,688 INFO Epoch 8 Step 50/168 - lr 0.000200 - loss 0.5610
2025-10-04 23:26:37,959 INFO Epoch 8 Step 100/168 - lr 0.000200 - loss 0.5557
2025-10-04 23:29:13,666 INFO Epoch 8 Step 150/168 - lr 0.000200 - loss 0.5516
2025-10-04 23:30:24,265 INFO Epoch 8/30 - lr 0.000200 - loss 0.5497 - val f1 0.8506
2025-10-04 23:33:10,200 INFO Epoch 9 Step 50/168 - lr 0.000200 - loss 0.5179
2025-10-04 23:35:57,829 INFO Epoch 9 Step 100/168 - lr 0.000200 - loss 0.5168
2025-10-04 23:38:39,453 INFO Epoch 9 Step 150/168 - lr 0.000200 - loss 0.5135
2025-10-04 23:39:44,629 INFO Epoch 9/30 - lr 0.000200 - loss 0.5116 - val f1 0.8686
2025-10-04 23:42:21,310 INFO Epoch 10 Step 50/168 - lr 0.000200 - loss 0.4818
2025-10-04 23:44:53,732 INFO Epoch 10 Step 100/168 - lr 0.000200 - loss 0.4769
2025-10-04 23:47:26,963 INFO Epoch 10 Step 150/168 - lr 0.000200 - loss 0.4744
2025-10-04 23:48:35,873 INFO Epoch 10/30 - lr 0.000200 - loss 0.4718 - val f1 0.8963
2025-10-04 23:51:13,813 INFO Epoch 11 Step 50/168 - lr 0.000200 - loss 0.4499
2025-10-04 23:53:52,092 INFO Epoch 11 Step 100/168 - lr 0.000200 - loss 0.4425
2025-10-04 23:56:22,135 INFO Epoch 11 Step 150/168 - lr 0.000200 - loss 0.4372
2025-10-04 23:57:30,875 INFO Epoch 11/30 - lr 0.000200 - loss 0.4350 - val f1 0.9083
2025-10-05 00:00:03,893 INFO Epoch 12 Step 50/168 - lr 0.000200 - loss 0.4133
2025-10-05 00:02:55,465 INFO Epoch 12 Step 100/168 - lr 0.000200 - loss 0.4074
2025-10-05 00:05:32,829 INFO Epoch 12 Step 150/168 - lr 0.000200 - loss 0.4023
2025-10-05 00:06:42,409 INFO Epoch 12/30 - lr 0.000200 - loss 0.3994 - val f1 0.9278
2025-10-05 00:09:12,233 INFO Epoch 13 Step 50/168 - lr 0.000200 - loss 0.3768
2025-10-05 00:11:43,608 INFO Epoch 13 Step 100/168 - lr 0.000200 - loss 0.3724
2025-10-05 00:14:12,643 INFO Epoch 13 Step 150/168 - lr 0.000200 - loss 0.3712
2025-10-05 00:15:27,740 INFO Epoch 13/30 - lr 0.000200 - loss 0.3709 - val f1 0.9369
2025-10-05 00:18:10,439 INFO Epoch 14 Step 50/168 - lr 0.000200 - loss 0.3512
2025-10-05 00:20:47,921 INFO Epoch 14 Step 100/168 - lr 0.000200 - loss 0.3485
2025-10-05 00:23:22,817 INFO Epoch 14 Step 150/168 - lr 0.000200 - loss 0.3432
2025-10-05 00:24:32,229 INFO Epoch 14/30 - lr 0.000200 - loss 0.3416 - val f1 0.9449
2025-10-05 00:27:06,447 INFO Epoch 15 Step 50/168 - lr 0.000200 - loss 0.3272
2025-10-05 00:29:44,932 INFO Epoch 15 Step 100/168 - lr 0.000200 - loss 0.3266
2025-10-05 00:32:23,680 INFO Epoch 15 Step 150/168 - lr 0.000200 - loss 0.3227
2025-10-05 00:33:37,435 INFO Epoch 15/30 - lr 0.000200 - loss 0.3222 - val f1 0.9558
2025-10-05 00:36:16,666 INFO Epoch 16 Step 50/168 - lr 0.000200 - loss 0.3105
2025-10-05 00:38:56,548 INFO Epoch 16 Step 100/168 - lr 0.000200 - loss 0.3048
2025-10-05 00:41:35,050 INFO Epoch 16 Step 150/168 - lr 0.000200 - loss 0.3014
2025-10-05 00:42:46,085 INFO Epoch 16/30 - lr 0.000200 - loss 0.3005 - val f1 0.9640
2025-10-05 00:45:26,340 INFO Epoch 17 Step 50/168 - lr 0.000200 - loss 0.2946
2025-10-05 00:48:06,425 INFO Epoch 17 Step 100/168 - lr 0.000200 - loss 0.2910
2025-10-05 00:50:46,347 INFO Epoch 17 Step 150/168 - lr 0.000200 - loss 0.2888
2025-10-05 00:51:55,977 INFO Epoch 17/30 - lr 0.000200 - loss 0.2880 - val f1 0.9672
2025-10-05 00:54:35,814 INFO Epoch 18 Step 50/168 - lr 0.000200 - loss 0.2793
2025-10-05 00:57:05,518 INFO Epoch 18 Step 100/168 - lr 0.000200 - loss 0.2762
2025-10-05 00:59:37,288 INFO Epoch 18 Step 150/168 - lr 0.000200 - loss 0.2740
2025-10-05 01:00:44,183 INFO Epoch 18/30 - lr 0.000200 - loss 0.2728 - val f1 0.9722
2025-10-05 01:03:14,920 INFO Epoch 19 Step 50/168 - lr 0.000200 - loss 0.2667
2025-10-05 01:05:49,325 INFO Epoch 19 Step 100/168 - lr 0.000200 - loss 0.2641
2025-10-05 01:08:22,116 INFO Epoch 19 Step 150/168 - lr 0.000200 - loss 0.2627
2025-10-05 01:09:30,337 INFO Epoch 19/30 - lr 0.000200 - loss 0.2623 - val f1 0.9772
2025-10-05 01:12:01,022 INFO Epoch 20 Step 50/168 - lr 0.000200 - loss 0.2555
2025-10-05 01:14:36,075 INFO Epoch 20 Step 100/168 - lr 0.000200 - loss 0.2545
2025-10-05 01:17:07,214 INFO Epoch 20 Step 150/168 - lr 0.000200 - loss 0.2523
2025-10-05 01:18:15,147 INFO Epoch 20/30 - lr 0.000200 - loss 0.2526 - val f1 0.9799
2025-10-05 01:20:46,589 INFO Epoch 21 Step 50/168 - lr 0.000200 - loss 0.2509
2025-10-05 01:23:15,707 INFO Epoch 21 Step 100/168 - lr 0.000200 - loss 0.2467
2025-10-05 01:25:46,195 INFO Epoch 21 Step 150/168 - lr 0.000200 - loss 0.2446
2025-10-05 01:26:54,916 INFO Epoch 21/30 - lr 0.000200 - loss 0.2435 - val f1 0.9815
2025-10-05 01:29:27,592 INFO Epoch 22 Step 50/168 - lr 0.000200 - loss 0.2440
2025-10-05 01:31:56,505 INFO Epoch 22 Step 100/168 - lr 0.000200 - loss 0.2398
2025-10-05 01:34:26,337 INFO Epoch 22 Step 150/168 - lr 0.000200 - loss 0.2376
2025-10-05 01:35:35,026 INFO Epoch 22/30 - lr 0.000200 - loss 0.2371 - val f1 0.9855
2025-10-05 01:38:08,383 INFO Epoch 23 Step 50/168 - lr 0.000200 - loss 0.2310
2025-10-05 01:40:41,549 INFO Epoch 23 Step 100/168 - lr 0.000200 - loss 0.2288
2025-10-05 01:43:11,707 INFO Epoch 23 Step 150/168 - lr 0.000200 - loss 0.2291
2025-10-05 01:44:21,027 INFO Epoch 23/30 - lr 0.000200 - loss 0.2292 - val f1 0.9879
2025-10-05 01:46:51,526 INFO Epoch 24 Step 50/168 - lr 0.000200 - loss 0.2303
2025-10-05 01:49:23,569 INFO Epoch 24 Step 100/168 - lr 0.000200 - loss 0.2290
2025-10-05 01:51:53,550 INFO Epoch 24 Step 150/168 - lr 0.000200 - loss 0.2276
2025-10-05 01:53:03,500 INFO Epoch 24/30 - lr 0.000200 - loss 0.2270 - val f1 0.9902
2025-10-05 01:55:34,769 INFO Epoch 25 Step 50/168 - lr 0.000200 - loss 0.2232
2025-10-05 01:58:03,993 INFO Epoch 25 Step 100/168 - lr 0.000200 - loss 0.2212
2025-10-05 02:00:33,267 INFO Epoch 25 Step 150/168 - lr 0.000200 - loss 0.2212
2025-10-05 02:01:41,610 INFO Epoch 25/30 - lr 0.000200 - loss 0.2208 - val f1 0.9888
2025-10-05 02:04:10,122 INFO Epoch 26 Step 50/168 - lr 0.000200 - loss 0.2168
2025-10-05 02:06:46,291 INFO Epoch 26 Step 100/168 - lr 0.000200 - loss 0.2164
2025-10-05 02:09:14,173 INFO Epoch 26 Step 150/168 - lr 0.000200 - loss 0.2165
2025-10-05 02:10:23,789 INFO Epoch 26/30 - lr 0.000200 - loss 0.2165 - val f1 0.9911
2025-10-05 02:12:54,695 INFO Epoch 27 Step 50/168 - lr 0.000200 - loss 0.2158
2025-10-05 02:15:26,868 INFO Epoch 27 Step 100/168 - lr 0.000200 - loss 0.2142
2025-10-05 02:17:58,089 INFO Epoch 27 Step 150/168 - lr 0.000200 - loss 0.2145
2025-10-05 02:19:06,904 INFO Epoch 27/30 - lr 0.000200 - loss 0.2145 - val f1 0.9936
2025-10-05 02:21:38,097 INFO Epoch 28 Step 50/168 - lr 0.000200 - loss 0.2118
2025-10-05 02:24:08,545 INFO Epoch 28 Step 100/168 - lr 0.000200 - loss 0.2099
2025-10-05 02:26:40,265 INFO Epoch 28 Step 150/168 - lr 0.000200 - loss 0.2098
2025-10-05 02:27:48,238 INFO Epoch 28/30 - lr 0.000200 - loss 0.2097 - val f1 0.9937
2025-10-05 02:30:18,009 INFO Epoch 29 Step 50/168 - lr 0.000200 - loss 0.2080
2025-10-05 02:32:48,111 INFO Epoch 29 Step 100/168 - lr 0.000200 - loss 0.2081
2025-10-05 02:35:17,788 INFO Epoch 29 Step 150/168 - lr 0.000200 - loss 0.2082
2025-10-05 02:36:26,504 INFO Epoch 29/30 - lr 0.000200 - loss 0.2076 - val f1 0.9943
2025-10-05 02:38:56,078 INFO Epoch 30 Step 50/168 - lr 0.000200 - loss 0.2048
2025-10-05 02:41:25,034 INFO Epoch 30 Step 100/168 - lr 0.000200 - loss 0.2073
2025-10-05 02:43:55,766 INFO Epoch 30 Step 150/168 - lr 0.000200 - loss 0.2069
2025-10-05 02:45:04,616 INFO Epoch 30/30 - lr 0.000200 - loss 0.2066 - val f1 0.9923
2025-10-05 02:45:04,666 INFO Classification report:
                precision    recall  f1-score   support

     CANDIDATE       0.98      0.99      0.99      3886
     CONFIRMED       0.99      1.00      0.99      5758
FALSE POSITIVE       1.00      0.99      0.99     11752

      accuracy                           0.99     21396
     macro avg       0.99      0.99      0.99     21396
  weighted avg       0.99      0.99      0.99     21396

